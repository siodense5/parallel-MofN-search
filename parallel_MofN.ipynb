{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Set up sparkcontext, add necessary credentials here for use on your platform of choice"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark import SparkContext\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "sc = SparkContext(appName=\"parallel_MofN\")\n",
    "\n",
    "'''\n",
    "\n",
    "ADD REQUIRED SETUP FOR SPARK FOR YOUR CLOUD SERVICE IF NECESSARY\n",
    "\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get necessary inputs to run the search. Need weights, input layer activations, output layer activations, and the target layer activations. All values and parameters are stored as 2d or 1d arrays in csv files. Convolutional layers are flattened if necessary. To load a layer to test change the respective paths to the location of the required file. More information on the proper format of arrays can be found in the readme"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "weight_path=\"https://raw.githubusercontent.com/siodense5/parallel-MofN-search/blob/master/data/cars_fc_1_weights.csv\"\n",
    "input_path=\"https://raw.githubusercontent.com/siodense5/parallel-MofN-search/blob/master/data/processed_car_data.csv\"\n",
    "layerout_path=\"https://raw.githubusercontent.com/siodense5/parallel-MofN-search/blob/master/data/cars_fc_1_output.csv\"\n",
    "labels_path=\"https://raw.githubusercontent.com/siodense5/parallel-MofN-search/blob/master/data/cars_fc_3_output.csv\"\n",
    "\n",
    "w=pd.get_csv(weight_path).values\n",
    "test_inputs=pd.get_csv(input_path).values\n",
    "test_lo=pd.get_csv(layerout_path).values\n",
    "test_labels=pd.get_csv(labels_path).values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Set up the test parameters. For each feature in a convolultional layer we select the neuron with the maximum information\n",
    "gain to test. If the layer is fully connected feature size will be 1 and every neuron in test_lo will be tested.\n",
    "We generate the output examples using the splits calculated in the previous step on the selected output neurons.\n",
    "We then generate splits for the input neurons using the information gain with respect to the output neurons.\n",
    "Since the split that maximizes the information gain for a given output neuron might not be the split that maximizes\n",
    "the information gain for a different output neuron we generate a different set of splits for each output neuron.\n",
    "The output of this is an array of binary output examples generated by the output splits and a list of arrays of\n",
    "input examples generated by the input splits for each output neuron"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import subsample_flatten\n",
    "import generate_splits\n",
    "\n",
    "#Change these parameters for each layer, for convolutional layers set subsample=True, for the final layer set Final_Layer=True\n",
    "#If the layer is convolutional then set num_input_channels to the number of channels in the input and the feature dimension \n",
    "#to the size of dimension of the input (we assume that the input is 2 dimensional with the same number of features in each dimension)\n",
    "Final_Layer=False\n",
    "subsample=False\n",
    "\n",
    "num_input_channels=32\n",
    "feature_dimension=3\n",
    "feature_size=feature_dimension*feature_dimension\n",
    "\n",
    "\n",
    "num_hidden=w.shape[1]\n",
    "num_visible=w.shape[0]\n",
    "num_examples=test_inputs.shape[0]\n",
    "num_labels=test_labels.shape[1]\n",
    "\n",
    "if Final_Layer:\n",
    "    \n",
    "    for i in range(test_labels.shape[0]):\n",
    "        \n",
    "        #Convert to one-hot when extracting from the final layer\n",
    "        test_labels[i,:]= (test_labels[i,:]==np.max(test_labels[i,:]))\n",
    "        outputs=test_labels\n",
    "        splits=generate_splits.generate_splits_parallel(test_inputs,outputs,2)[:,0,:]\n",
    "        ins=[test_inputs]*num_hidden\n",
    "        \n",
    "else:\n",
    "    \n",
    "    test_labels=np.reshape(np.argmax(test_labels,axis=1),[num_examples,1])\n",
    "    o=generate_splits_parallel(test_lo,test_labels,num_labels)\n",
    "\n",
    "\n",
    "    #If the layer is convolution we must take subsamples of the input image to test on.\n",
    "    #To do this, for each filter, we unflatten the input array, use information gain to \n",
    "    #select an image patch to test for each filter, for each example input, pad the image \n",
    "    #patch if necessary and flatten it. Return the set of example image patches in a 2d array\n",
    "  
    "    if subsample:\n",
    "\n",
    "        ou=np.array(o)\n",
    "\n",
    "        best_output_splits=ou[:,0,0]\n",
    "        information_gains=ou[:,1,0]\n",
    "\n",
    "        indicies=[]\n",
    "\n",
    "        #For each filter find the input image patch with maximum information gain. The index is the pixel at the center\n",
    "        #of this image patch \n",
    "        for i in range(num_hidden):\n",
    "            indicies.append(i*feature_size+np.argmax(information_gains[i*feature_size:i*feature_size+feature_size]))\n",
    "\n",
    "        outputs=test_lo[:,indicies]>best_output_splits[indicies]\n",
    "\n",
    "        splits=[]\n",
    "        literals=[]\n",
    "\n",
    "        ins=[]\n",
    "        re_test_inputs=subsample_flatten.unflatten_inputs(test_inputs,[num_examples,feature_dimension,feature_dimension,num_input_channels])\n",
    "\n",
    "        for i in range(len(indicies)):\n",
    "\n",
    "            ins.append(subsample_flatten.subsample_flatten_arrays(re_test_inputs,[2,2],[2,2],num_input_channels,new_position=indicies[i]%feature_size))\n",
    "\n",
    "            splits.append(generate_splits.generate_splits_parallel(ins[-1],np.reshape(outputs[:,i],[num_examples,1]),2)[:,0,0])\n",
    "\n",
    "        splits=np.array(splits).T    \n",
    "\n",
    "\n",
    "    #If the layer in not convolution we require no subsampling and generate splits for every input neuron.\n",
    "    #Because the set of input neurons in this case does not depend on which hidden neuron we are using\n",
    "    #we can run the search in parallel\n",
    "    else:\n",
    "\n",
    "        ou=np.array(o)\n",
    "\n",
    "        best_output_splits=ou[:,0,0]\n",
    "        information_gains=ou[:,1,0]\n",
    "\n",
    "        outputs=test_lo>best_output_splits\n",
    "        \n",
    "        splits=generate_splits.generate_splits_parallel(test_inputs,outputs,2)[:,0,:]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally we convert the necessary data into lists in order to do perform parallel searches over them using lambda expressions. \n",
    "Because some of the examples might have a lot of hidden units we use test_hidden to select only a certain number of hidden units\n",
    "to test. If we want to test all hidden units at once then set start_rule=0 end_rule=num_hidden"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start_rule=0\n",
    "end_rule=16\n",
    "num_rules=end_rule-start_rule\n",
    "\n",
    "test_hidden=[i for i in range(start_rule,end_rule)]\n",
    "\n",
    "#In the previous step, if we were subsampling, ins contains num_hidden different input arrays,\n",
    "#if we are not subsampling then each of these arrays is identical which is set up here.\n",
    "if not subsample:\n",
    "\n",
    "    ins=[test_inputs]*num_hidden\n",
    "\n",
    "test_outputs=outputs[:,test_hidden]\n",
    "\n",
    "weight_list=[w[:,h] for h in test_hidden]\n",
    "\n",
    "test_ins=[ins[i] for i in test_hidden]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Set up the list of rules to test and the functions used to compute the loss of each rule. Functions computing the error by finding the coordinates of positive and negative literals in a rule. For each input, count the positive literals whose input is greater than the split at that coordinate and the negative literals whose input is less than the split at that coordinate. If the sum is at least M then the rule outputs True and false otherwise. The error is percentage of rule outputs that are different than the outputs generated by the network. \n",
    "\n",
    "The complexity is the normalized length of the DNF of the rule"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#set up list of rules\n",
    "sort_indicies = lambda w : [j[0] for j in sorted(enumerate(abs(w)), key=lambda x:x[1], reverse=True)]\n",
    "sorted_indicies=[sort_indicies(w) for w in weight_list]\n",
    "                                           \n",
    "rule_bodies_M=[[N,M,i] for i in range(num_rules) for N in range(num_visible_test+1) for M in range(0,N+2)]  \n",
    "\n",
    "#functions to compute the error of a rule positive_indicies returns input indicies corresponding to\n",
    "#positive(unnegated) literals in the rule and negative_indicies returns the indicies corresponding to\n",
    "#negative(negated) literals in the rule. test_rule_output takes a rule and a set of input examples, \n",
    "#counts the number of positive indicies in an example that are greater than their corresponding splits\n",
    "#and the number of negative indicies less than their splits, adds the two and compares them to the value\n",
    "#of M for the rule. If the value is greater than or equal to M then the output is 1 and 0 otherwise\n",
    "positive_indicies = lambda rule: [sorted_indicies[rule[2]][i] for i in np.where(weight_list[rule[2]][sorted_indicies[rule[2]][0:rule[0]]]>0)[0].tolist()]\n",
    "negative_indicies = lambda rule: [sorted_indicies[rule[2]][i] for i in np.where(weight_list[rule[2]][sorted_indicies[rule[2]][0:rule[0]]]<0)[0].tolist()]\n",
    "\n",
    "compute_test_rule_output = lambda rule: np.count_nonzero((test_ins[rule[2]][:,positive_indicies(rule)]>=splits[positive_indicies(rule),rule[2]])==1,axis=1) +np.count_nonzero((test_ins[rule[2]][:,negative_indicies(rule)]<splits[negative_indicies(rule),rule[2]])==1,axis=1) >= rule[1]\n",
    "compute_test_error = lambda test_rules_output, test_output: np.abs(test_rules_output-test_output).sum(0)/num_examples\n",
    "\n",
    "\n",
    "#functions to compute the complexity of a rule. The unnormalized complexity of a rule is the length of\n",
    "#its DNF which is M*(N choose M). Max complexity calculates the maximum of this value assuming n input\n",
    "#neurons, compute_complexity calculates the length of the DNF and divides by max_complexity to normalize\n",
    "#The logarithm is taken in the numerator and denominator to control for growth\n",
    "N_choose_M=lambda N,M: (np.math.factorial(N)//(np.math.factorial(N-M)*np.math.factorial(M)))\n",
    "\n",
    "max_complexity_M=np.ceil((num_visible+1)/2)\n",
    "max_complexity=np.math.log(int(max_complexity_M)* N_choose_M(num_visible,max_complexity_M))\n",
    "compute_complexity = lambda N,M : 0 if (M==0 or M > N) else np.math.log(int(M)*N_choose_M(N,M))/max_complexity \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Parallelize and run the search using the previously defined functions to compute the complexity and accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rdd1=sc.parallelize(rule_bodies_M,5)\n",
    "\n",
    "rdd2=rdd1.map(lambda rule: [rule, compute_test_error(compute_test_rule_output(rule),(test_outputs.T[rule[2]])), compute_complexity(rule[0],rule[1])])\n",
    "\n",
    "ecrules=rdd2.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next we need to compute the loss using a set of complexity penalty values and return the rule with the best loss for each penalty value. In our implementation we use the following function adapted from\n",
    "https://gist.github.com/Juanlu001/562d1ec55be970403442"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Reduce by key.\n",
    "Equivalent to the Spark counterpart\n",
    "Inspired by http://stackoverflow.com/q/33648581/554319\n",
    "1. Sort by key\n",
    "2. Group by key yielding (key, grouper)\n",
    "3. For each pair yield (key, reduce(func, last element of each grouper))\n",
    "\"\"\"\n",
    "\n",
    "def reduceByKey(func, iterable):\n",
    "\n",
    "    get_first = lambda p: p[0]\n",
    "    get_second = lambda p: p[1]\n",
    "    # iterable.groupBy(_._1).map(l => (l._1, l._2.map(_._2).reduce(func)))\n",
    "    return map(\n",
    "        lambda l: (l[0], reduce(func, map(get_second, l[1]))),\n",
    "        groupby(sorted(iterable, key=get_first), get_first)\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "#Change values in penalty_list to test loss functions of different weights, some trial and error might be required to find \n",
    "#a set of penalty values that shows the relationship between complexity and accuracy\n",
    "penalty_list=[0, 0.1,0.2,1,5,1000]\n",
    "best_rules=[]\n",
    "for penalty in penalty_list:\n",
    "    \n",
    "    #compute the loss of each rule using a weighted sum of the error and complexity weighted by penalty, select the rule with minimum loss for each target neuron\n",
    "    prules=list(map(lambda rule: (rule[0][2],[rule[0],rule[1],rule[2],rule[1]+penalty*rule[2]]),ecrules))\n",
    "    prules=list(reduceByKey(lambda a,b : a if (a[3]<=b[3]) else b,prules))\n",
    "    prules=[rule[1] for rule in prules]\n",
    "\n",
    "    #append the set of optimal rules for the parameter penalty\n",
    "    best_rules.append(prules)\n",
    "\n",
    "\n",
    "complexity=[]\n",
    "error=[]\n",
    "#for each set of optimal rules given for a value of penalty, average the error and complexity of the optimal rules\n",
    "for rules in best_rules:    \n",
    "    average_error=0\n",
    "    average_complexity=0     \n",
    "    \n",
    "    for rule in rules:\n",
    "        average_error+=rule[1]\n",
    "        average_complexity+=rule[2]\n",
    "    \n",
    "    #list the averge error and complexity for each optimal rule\n",
    "    error.append(average_error/num_rules)\n",
    "    complexity.append(average_complexity/num_rules)\n",
    "\n",
    "print(\"Average Error/Average Complexity\", error,complexity)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plot the average error of the rules as a function of the average complexity. This allows us to see the relationship between how complex the rules are and how accurately they explain the neurons in the target layer. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(complexity,error)\n",
    "plt.yaxis(\"average error\")\n",
    "plt.xaxis(\"average complexity\")\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
